{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c10b768-f5b4-43bc-a785-99077422ce78",
   "metadata": {},
   "source": [
    "# Lesson 3: Chatbot Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14",
   "metadata": {},
   "source": [
    "In this lesson, you will familiarize yourself with the chatbot example you will work on during this course. The example includes the tool definitions and execution, as well as the chatbot code. Make sure to interact with the chatbot at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f163a-87af-4e0c-87ed-1624c150c572",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549a7f46-74b3-4a1d-b084-055c99e3c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43905e-56f3-404c-a322-f038055e9b1c",
   "metadata": {},
   "source": [
    "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the `papers` directory. The tool does not download the papers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886633b8-ce67-4343-822d-cc3f98f953fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers/computers/papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1312.3300v1', '2207.05241v1', '2012.10468v1', '2009.00041v1', '2009.08005v1']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"computers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb83565-69af-47f3-9ba3-a96965cff7df",
   "metadata": {},
   "source": [
    "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Numerical Reproducibility and Parallel Computations: Issues for Interval Algorithms\",\\n  \"authors\": [\\n    \"Nathalie Revol\",\\n    \"Philippe Th\\\\u00e9veny\"\\n  ],\\n  \"summary\": \"What is called \\\\\"numerical reproducibility\\\\\" is the problem of getting the same result when the scientific computation is run several times, either on the same machine or on different machines, with different types and numbers of processing units, execution environments, computational loads etc. This problem is especially stringent for HPC numerical simulations. In what follows, the focus is on parallel implementations of interval arithmetic using floating-point arithmetic. For interval computations, numerical reproducibility is of course an issue for testing and debugging purposes. However, as long as the computed result encloses the exact and unknown result, the inclusion property, which is the main property of interval arithmetic, is satisfied and getting bit for bit identical results may not be crucial. Still, implementation issues may invalidate the inclusion property. Several ways to preserve the inclusion property are presented, on the example of the product of matrices with interval coefficients.\",\\n  \"pdf_url\": \"https://arxiv.org/pdf/1312.3300v1\",\\n  \"published\": \"2013-12-11\"\\n}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('1312.3300v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2260-452d-472a-b56e-326479cb18c9",
   "metadata": {},
   "source": [
    "Here are the schema of each tool which you will provide to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5bdea5f-e93a-4018-8c13-00d5ee10c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2",
   "metadata": {},
   "source": [
    "## Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4",
   "metadata": {},
   "source": [
    "This code handles tool mapping and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c90790c0-efc4-4068-9c00-d2592d80bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31",
   "metadata": {},
   "source": [
    "## Chatbot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087",
   "metadata": {},
   "source": [
    "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe662400-8506-464e-a3da-75a3d8848bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv() \n",
    "client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175586b4-acdf-4103-8039-134478a4f797",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12a896e0-3f56-417e-aa51-c61756048593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-sonnet-4-5-20250929', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    \n",
    "    while response.stop_reason == 'tool_use':\n",
    "        # Collect all content (text and tool_use blocks)\n",
    "        assistant_content = []\n",
    "        tool_results = []\n",
    "\n",
    "        for content in response.content:\n",
    "            if content.type == 'text':\n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "            elif content.type == 'tool_use':\n",
    "                assistant_content.append(content)\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                tool_results.append({\n",
    "                    \"type\": \"tool_result\",\n",
    "                    \"tool_use_id\": tool_id,\n",
    "                    \"content\": result\n",
    "                })\n",
    "        \n",
    "        # Add the assistant message with ALL tool_use blocks\n",
    "        messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "        \n",
    "        # Add the user message with ALL tool_result blocks\n",
    "        messages.append({\"role\": \"user\", \"content\": tool_results})\n",
    "        \n",
    "        # Get the next response\n",
    "        response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-sonnet-4-5-20250929', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    \n",
    "    # Print final text response\n",
    "    for content in response.content:\n",
    "        if content.type == 'text':\n",
    "            print(content.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9",
   "metadata": {},
   "source": [
    "### Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16979cdc-81e9-432b-ba7f-e810b52961e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3",
   "metadata": {},
   "source": [
    "Feel free to interact with the chatbot. Here's an example query: \n",
    "\n",
    "- Search for 2 papers on \"LLM interpretability\"\n",
    "\n",
    "To access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  Ayurveda \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll search for papers related to Ayurveda on arXiv.\n",
      "Calling tool search_papers with args {'topic': 'Ayurveda'}\n",
      "Results are saved in: papers/ayurveda/papers_info.json\n",
      "I found 5 papers related to Ayurveda. Let me retrieve detailed information about each of them.\n",
      "Calling tool extract_info with args {'paper_id': '2207.14615v3'}\n",
      "Calling tool extract_info with args {'paper_id': '2511.02374v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2412.17005v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2510.25409v2'}\n",
      "Calling tool extract_info with args {'paper_id': '2108.09747v1'}\n",
      "Here are **5 papers related to Ayurveda** found on arXiv:\n",
      "\n",
      "---\n",
      "\n",
      "### 1. **Structural investigation of Ayurveda Lauha (Iron) Bhasma**\n",
      "- **Authors:** M. K. Tiwari, Arjun Singh, Ajay Khooha, U K Goutam\n",
      "- **Published:** July 29, 2022\n",
      "- **Summary:** This paper investigates the structural properties of Lauha (Iron) bhasma, an Ayurvedic preparation used to treat iron deficiency. Using X-ray techniques and SEM, researchers found that the traditional preparation process converts metallic iron into magnetite nanoparticles. The study suggests potential applications in cancer treatment through targeted cell killing using magnetic fields or X-rays.\n",
      "- **PDF:** [Download](https://arxiv.org/pdf/2207.14615v3)\n",
      "\n",
      "---\n",
      "\n",
      "### 2. **AyurParam: A State-of-the-Art Bilingual Language Model for Ayurveda**\n",
      "- **Authors:** Mohd Nauman, Sravan Gvm, Vijay Devane, and others\n",
      "- **Published:** November 4, 2025\n",
      "- **Summary:** Introduces AyurParam-2.9B, a specialized bilingual (English-Hindi) language model fine-tuned for Ayurvedic knowledge. The model was trained on curated classical texts and clinical guidance, demonstrating superior performance on BhashaBench-Ayur compared to other open-source models in its class, highlighting the importance of domain-specific AI adaptation for traditional medical systems.\n",
      "- **PDF:** [Download](https://arxiv.org/pdf/2511.02374v1)\n",
      "\n",
      "---\n",
      "\n",
      "### 3. **Investigation of phytochemicals, spectral properties, anticancer, antidiabetic, and antimicrobial activities of chosen Ayurvedic remedies**\n",
      "- **Authors:** T. H. Mohamed Ahadu Shareef, Irfan Navabshan, M Mohamed Divan Masood, and others\n",
      "- **Published:** December 22, 2024\n",
      "- **Summary:** Analyzes three Ayurvedic products (Triphala, Hinguvachadi Churnam, and Jirakadyarishtam) using GC-MS and LC-MS to identify bioactive compounds. The study evaluates their antimicrobial, anticancer, and anti-diabetic properties, finding significant antibacterial and antifungal activities, as well as Î±-glucosidase inhibitory effects.\n",
      "- **PDF:** [Download](https://arxiv.org/pdf/2412.17005v1)\n",
      "\n",
      "---\n",
      "\n",
      "### 4. **BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains**\n",
      "- **Authors:** Vijay Devane, Mohd Nauman, Bhargav Patel, and others\n",
      "- **Published:** October 29, 2025\n",
      "- **Summary:** Introduces BhashaBench V1, a bilingual benchmark for evaluating LLMs on India-specific domains including Ayurveda. The benchmark contains 74,166 Q&A pairs across Agriculture, Legal, Finance, and Ayurveda. Results show significant performance gaps, with models achieving only 59.74% accuracy in Ayurveda, highlighting challenges in specialized domain understanding.\n",
      "- **PDF:** [Download](https://arxiv.org/pdf/2510.25409v2)\n",
      "\n",
      "---\n",
      "\n",
      "### 5. **Neuromodulators in food ingredients: insights from network pharmacological evaluation of Ayurvedic herbs**\n",
      "- **Authors:** Neha Choudhary, Vikram Singh\n",
      "- **Published:** August 22, 2021\n",
      "- **Summary:** Uses network pharmacology to evaluate 34,472 phytochemicals from 3,038 Ayurvedic herbs for neurological disease treatment. The study identifies 219 neuro-phytoregulators targeting 102 proteins involved in neurological disorders, with key herbs including Cannabis sativa, Glycyrrhiza glabra, and Papaver somniferum showing potential for drug discovery against neurological conditions.\n",
      "- **PDF:** [Download](https://arxiv.org/pdf/2108.09747v1)\n",
      "\n",
      "---\n",
      "\n",
      "These papers span diverse aspects of Ayurveda research, from traditional preparations and AI applications to phytochemical analysis and neurological treatments.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  Hypertension\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll search for papers on hypertension for you.\n",
      "Calling tool search_papers with args {'topic': 'hypertension'}\n",
      "Results are saved in: papers/hypertension/papers_info.json\n",
      "I found 5 papers related to hypertension. Let me retrieve detailed information about each of them.\n",
      "Calling tool extract_info with args {'paper_id': '2411.11863v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2111.10471v1'}\n",
      "Calling tool extract_info with args {'paper_id': '1305.0727v2'}\n",
      "Calling tool extract_info with args {'paper_id': '2510.19302v2'}\n",
      "Calling tool extract_info with args {'paper_id': '2007.10717v1'}\n",
      "Here are 5 recent research papers on hypertension:\n",
      "\n",
      "## 1. **Longitudinal Wrist PPG Analysis for Reliable Hypertension Risk Screening Using Deep Learning**\n",
      "**Authors:** Hui Lin, Jiyang Li, Ramy Hussein, et al.  \n",
      "**Published:** November 2024  \n",
      "**Summary:** This study uses deep learning models (ResNet and Transformer) to analyze wrist PPG data from smartwatches for hypertension screening. Tested on 448 subjects with over 68k instances, the compact ResNet model significantly outperformed traditional methods in distinguishing between healthy and abnormal cases, offering a cuffless, continuous blood pressure monitoring solution.  \n",
      "[PDF Link](https://arxiv.org/pdf/2411.11863v1)\n",
      "\n",
      "## 2. **SNPs Filtered by Allele Frequency Improve the Prediction of Hypertension Subtypes**\n",
      "**Authors:** Yiming Li, Sanjiv J. Shah, Donna Arnett, et al.  \n",
      "**Published:** November 2021  \n",
      "**Summary:** Research on 911 African Americans and 1,171 European Americans examining genetic and environmental factors in hypertension subtypes. The study built classification models to understand the genetic landscape of hypertension, potentially aiding personalized diagnosis and treatment.  \n",
      "[PDF Link](https://arxiv.org/pdf/2111.10471v1)\n",
      "\n",
      "## 3. **Arterial Stiffening Provides Sufficient Explanation for Primary Hypertension**\n",
      "**Authors:** Klas H. Pettersen, Scott M. Bugenhagen, Javaid Nauman, et al.  \n",
      "**Published:** May 2013  \n",
      "**Summary:** Using computational models of the baroreceptor reflex and circulatory mechanics, this study demonstrates that arterial stiffening alone can explain age-related hypertension. The findings suggest a mechanogenic etiology for primary hypertension and support targeting the baroreflex response for treatment.  \n",
      "[PDF Link](https://arxiv.org/pdf/1305.0727v2)\n",
      "\n",
      "## 4. **Cardiocirculatory Computational Models for the Study of Hypertension**\n",
      "**Authors:** Simone Celora, Andrea Tonini, Francesco Regazzoni, et al.  \n",
      "**Published:** October 2025  \n",
      "**Summary:** Development of patient-specific cardiocirculatory models as Digital Twins for hypertension. The study combines 0D and 3D-0D electromechanical models to simulate systemic, pulmonary, and renovascular hypertension across different severity levels, providing clinically meaningful insights for real-time hypertension control.  \n",
      "[PDF Link](https://arxiv.org/pdf/2510.19302v2)\n",
      "\n",
      "## 5. **A Radiomics Approach to Analyze Cardiac Alterations in Hypertension**\n",
      "**Authors:** Irem Cetin, Steffen E. Petersen, Sandy Napel, et al.  \n",
      "**Published:** July 2020  \n",
      "**Summary:** This paper uses radiomics with machine learning to identify subtle cardiac structural and tissue changes in hypertensive patients that conventional imaging cannot detect. The approach shows potential for improved understanding of hypertension's longitudinal effects on cardiovascular health.  \n",
      "[PDF Link](https://arxiv.org/pdf/2007.10717v1)\n",
      "\n",
      "These papers cover various aspects of hypertension research including wearable monitoring, genetic factors, computational modeling, and advanced imaging techniques.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  quit\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34df7890-4b4c-4ec9-b06f-abc8c4a290e8",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#f7fff8; padding:15px; border-width:3px; border-color:#e0f0e0; border-style:solid; border-radius:6px\"> ðŸš¨\n",
    "&nbsp; <b>Different Run Results:</b> The output generated by AI chat models can vary with each execution due to their dynamic, probabilistic nature. Don't be surprised if your results differ from those shown in the video.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb34ee2d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "<p> ðŸ’» &nbsp; <b> To Access the <code>requirements.txt</code> file or the <code>papers</code> folder: </b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Open\"</em> and finally 3) click on <em>\"L3\"</em>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508916f3-8fa1-4e21-bfa7-081a810bc36c",
   "metadata": {},
   "source": [
    "In the next lessons, you will take out the tool definitions to wrap them in an MCP server. Then you will create an MCP client inside the chatbot to make the chatbot MCP compatible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d207b-e07d-49ff-bb03-7954aa86c167",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Guide on how to implement tool use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#how-to-implement-tool-use)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e5135e-01c3-4632-9f83-a1e6dd811049",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff6ff; padding:13px; border-width:3px; border-color:#efe6ef; border-style:solid; border-radius:6px\">\n",
    "\n",
    "\n",
    "<p> â¬‡ &nbsp; <b>Download Notebooks:</b> 1) click on the <em>\"File\"</em> option on the top menu of the notebook and then 2) click on <em>\"Download as\"</em> and select <em>\"Notebook (.ipynb)\"</em>.</p>\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
